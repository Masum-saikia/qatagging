{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:01:55.957198Z",
     "start_time": "2024-11-11T18:01:55.941222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os"
   ],
   "id": "b52011cafb23d2ff",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:01:56.382772Z",
     "start_time": "2024-11-11T18:01:56.081859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "data = pd.read_parquet(\"auto_tagging_data_v2.parquet\")\n",
    "all_tags = sorted(list(set(tag for tags in data['Tags'] for tag in tags)))\n",
    "number_of_tags = len(all_tags)"
   ],
   "id": "91d9d5007389f979",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T10:12:03.626396Z",
     "start_time": "2024-11-13T10:12:03.595165Z"
    }
   },
   "cell_type": "code",
   "source": "data.head(10)",
   "id": "443f8efa5cb05bba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Id                                              Title  \\\n",
       "0    6  The Two Cultures: statistics vs. machine learn...   \n",
       "1   21                     Forecasting demographic census   \n",
       "2   22  Bayesian and frequentist reasoning in plain En...   \n",
       "3   31  What is the meaning of p values and t values i...   \n",
       "4   36  Examples for teaching: Correlation does not me...   \n",
       "5   93  Robust nonparametric estimation of hazard/surv...   \n",
       "6   95  How Large a Difference Can Be Expected Between...   \n",
       "7  103     What is your favorite data visualization blog?   \n",
       "8  113  What are some good frameworks for method selec...   \n",
       "9  114        What statistical blogs would you recommend?   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>Last year, I read a blog post from <a href=...   \n",
       "1  <p>What are some of the ways to forecast demog...   \n",
       "2  <p>How would you describe in plain English the...   \n",
       "3  <p>After taking a statistics course and then t...   \n",
       "4  <p>There is an old saying: \"Correlation does n...   \n",
       "5  <p>We're trying to use a Gaussian process to m...   \n",
       "6  <p>I have been using various GARCH-based model...   \n",
       "7  <p>What is the best blog on data visualization...   \n",
       "8  <p>I have been looking into theoretical framew...   \n",
       "9  <p>What statistical research blogs would you r...   \n",
       "\n",
       "                                                Tags  \n",
       "0                                 [machine-learning]  \n",
       "1                                      [forecasting]  \n",
       "2                                         [bayesian]  \n",
       "3  [hypothesis-testing, t-test, p-value, interpre...  \n",
       "4                                      [correlation]  \n",
       "5                          [nonparametric, survival]  \n",
       "6                                      [time-series]  \n",
       "7                   [data-visualization, references]  \n",
       "8                                 [machine-learning]  \n",
       "9                                       [references]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=...</td>\n",
       "      <td>[machine-learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demog...</td>\n",
       "      <td>[forecasting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain En...</td>\n",
       "      <td>&lt;p&gt;How would you describe in plain English the...</td>\n",
       "      <td>[bayesian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>What is the meaning of p values and t values i...</td>\n",
       "      <td>&lt;p&gt;After taking a statistics course and then t...</td>\n",
       "      <td>[hypothesis-testing, t-test, p-value, interpre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Examples for teaching: Correlation does not me...</td>\n",
       "      <td>&lt;p&gt;There is an old saying: \"Correlation does n...</td>\n",
       "      <td>[correlation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93</td>\n",
       "      <td>Robust nonparametric estimation of hazard/surv...</td>\n",
       "      <td>&lt;p&gt;We're trying to use a Gaussian process to m...</td>\n",
       "      <td>[nonparametric, survival]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95</td>\n",
       "      <td>How Large a Difference Can Be Expected Between...</td>\n",
       "      <td>&lt;p&gt;I have been using various GARCH-based model...</td>\n",
       "      <td>[time-series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>103</td>\n",
       "      <td>What is your favorite data visualization blog?</td>\n",
       "      <td>&lt;p&gt;What is the best blog on data visualization...</td>\n",
       "      <td>[data-visualization, references]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>113</td>\n",
       "      <td>What are some good frameworks for method selec...</td>\n",
       "      <td>&lt;p&gt;I have been looking into theoretical framew...</td>\n",
       "      <td>[machine-learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>114</td>\n",
       "      <td>What statistical blogs would you recommend?</td>\n",
       "      <td>&lt;p&gt;What statistical research blogs would you r...</td>\n",
       "      <td>[references]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T08:54:04.909608Z",
     "start_time": "2024-11-13T08:54:04.883088Z"
    }
   },
   "cell_type": "code",
   "source": "all_tags",
   "id": "9dfb3dd59ff9e40a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algorithms',\n",
       " 'anova',\n",
       " 'arima',\n",
       " 'autocorrelation',\n",
       " 'bayesian',\n",
       " 'binary-data',\n",
       " 'binomial',\n",
       " 'bootstrap',\n",
       " 'cart',\n",
       " 'categorical-data',\n",
       " 'chi-squared',\n",
       " 'classification',\n",
       " 'clustering',\n",
       " 'conditional-probability',\n",
       " 'confidence-interval',\n",
       " 'correlation',\n",
       " 'covariance',\n",
       " 'cox-model',\n",
       " 'cross-validation',\n",
       " 'data-mining',\n",
       " 'data-transformation',\n",
       " 'data-visualization',\n",
       " 'dataset',\n",
       " 'deep-learning',\n",
       " 'distributions',\n",
       " 'econometrics',\n",
       " 'estimation',\n",
       " 'expected-value',\n",
       " 'experiment-design',\n",
       " 'factor-analysis',\n",
       " 'feature-selection',\n",
       " 'forecasting',\n",
       " 'generalized-linear-model',\n",
       " 'goodness-of-fit',\n",
       " 'hypothesis-testing',\n",
       " 'inference',\n",
       " 'interaction',\n",
       " 'interpretation',\n",
       " 'least-squares',\n",
       " 'linear-model',\n",
       " 'logistic',\n",
       " 'machine-learning',\n",
       " 'mathematical-statistics',\n",
       " 'matlab',\n",
       " 'maximum-likelihood',\n",
       " 'mcmc',\n",
       " 'mean',\n",
       " 'missing-data',\n",
       " 'mixed-model',\n",
       " 'model',\n",
       " 'model-selection',\n",
       " 'modeling',\n",
       " 'monte-carlo',\n",
       " 'multilevel-analysis',\n",
       " 'multiple-comparisons',\n",
       " 'multiple-regression',\n",
       " 'multivariate-analysis',\n",
       " 'neural-networks',\n",
       " 'nonlinear-regression',\n",
       " 'nonparametric',\n",
       " 'normal-distribution',\n",
       " 'optimization',\n",
       " 'ordinal',\n",
       " 'outliers',\n",
       " 'p-value',\n",
       " 'panel-data',\n",
       " 'pca',\n",
       " 'pdf',\n",
       " 'poisson',\n",
       " 'prediction',\n",
       " 'predictive-models',\n",
       " 'probability',\n",
       " 'proportion',\n",
       " 'python',\n",
       " 'r',\n",
       " 'random-effects-model',\n",
       " 'random-forest',\n",
       " 'random-variable',\n",
       " 'references',\n",
       " 'regression',\n",
       " 'regression-coefficients',\n",
       " 'repeated-measures',\n",
       " 'residuals',\n",
       " 'sample-size',\n",
       " 'sampling',\n",
       " 'self-study',\n",
       " 'simulation',\n",
       " 'spss',\n",
       " 'standard-deviation',\n",
       " 'standard-error',\n",
       " 'stata',\n",
       " 'statistical-significance',\n",
       " 'stochastic-processes',\n",
       " 'survey',\n",
       " 'survival',\n",
       " 'svm',\n",
       " 't-test',\n",
       " 'terminology',\n",
       " 'time-series',\n",
       " 'variance']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:03:51.160184Z",
     "start_time": "2024-11-11T18:01:56.382772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load a pre-trained sentence transformer model for embedding\n",
    "retrieval_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode all data bodies for retrieval indexing\n",
    "corpus_embeddings = retrieval_model.encode(data['Body'].tolist())\n",
    "dimension = corpus_embeddings.shape[1]\n",
    "\n",
    "# Initialize FAISS index\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(corpus_embeddings))"
   ],
   "id": "4f89056fc5857825",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:03:51.229925Z",
     "start_time": "2024-11-11T18:03:51.222661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retrieve context function\n",
    "def retrieve_context(input_text, top_k=3):\n",
    "    input_embedding = retrieval_model.encode([input_text])\n",
    "    _, top_k_indices = index.search(np.array(input_embedding), top_k)\n",
    "    return [data['Body'].iloc[i] for i in top_k_indices[0]]\n",
    "\n",
    "\n",
    "# Function to augment text with context\n",
    "def augment_with_context(input_text):\n",
    "    context = retrieve_context(input_text)\n",
    "    return input_text + \" \" + \" \".join(context)\n",
    "\n",
    "\n",
    "def encode_tags(tags):\n",
    "    encoding = np.zeros(len(all_tags))\n",
    "    for tag in tags:\n",
    "        if tag in all_tags:\n",
    "            index = all_tags.index(tag)\n",
    "            encoding[index] = 1\n",
    "    return encoding"
   ],
   "id": "7fe51233c6adaa89",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:03:57.714497Z",
     "start_time": "2024-11-11T18:03:51.342277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = data['Tags'].apply(encode_tags)\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=number_of_tags)"
   ],
   "id": "ba0d49c29a4b2d30",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:03:57.762184Z",
     "start_time": "2024-11-11T18:03:57.732210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.2,\n",
    ")\n",
    "lora_model = get_peft_model(model, lora_config)"
   ],
   "id": "169e125be5f3b05b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T18:03:57.840402Z",
     "start_time": "2024-11-11T18:03:57.824320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AutoTaggingDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = augment_with_context(self.texts[idx])  # Augment input text with context\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        \n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        \n",
    "        return inputs, label"
   ],
   "id": "591c008410e4c48f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-11T22:57:40.059423Z",
     "start_time": "2024-11-11T18:03:57.903308Z"
    }
   },
   "source": [
    "# Initialize DataLoader\n",
    "dataset = AutoTaggingDataset(data[\"Body\"], labels, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lora_model.to(device)\n",
    "\n",
    "optimizer = AdamW(lora_model.parameters(), lr=2e-4, weight_decay=0.001)\n",
    "epochs = 10\n",
    "warmup_steps = int(0.1 * len(dataloader))\n",
    "total_steps = len(dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "patience = 2\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    lora_model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs, labels = batch\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = lora_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = torch.nn.BCEWithLogitsLoss()(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(lora_model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        preds = (probs > 0.5).astype(int)\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_loss / len(dataloader)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    exact_match_ratio = np.mean(np.all(all_preds == all_labels, axis=1))\n",
    "    label_accuracy = np.mean(np.equal(all_preds, all_labels).astype(float), axis=0).mean()\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    if avg_train_loss < best_val_loss:\n",
    "        best_val_loss = avg_train_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {avg_train_loss:.4f}, Exact Match Ratio: {exact_match_ratio:.4f}, \"f\"Label-based Accuracy: {label_accuracy:.4f}, F1 Score: {f1:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abheek\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0880, Exact Match Ratio: 0.0229, Label-based Accuracy: 0.9771, F1 Score: 0.0289\n",
      "Epoch 2, Loss: 0.0662, Exact Match Ratio: 0.0827, Label-based Accuracy: 0.9819, F1 Score: 0.1126\n",
      "Epoch 3, Loss: 0.0611, Exact Match Ratio: 0.1146, Label-based Accuracy: 0.9826, F1 Score: 0.1888\n",
      "Epoch 4, Loss: 0.0582, Exact Match Ratio: 0.1326, Label-based Accuracy: 0.9831, F1 Score: 0.2427\n",
      "Epoch 5, Loss: 0.0562, Exact Match Ratio: 0.1420, Label-based Accuracy: 0.9834, F1 Score: 0.2825\n",
      "Epoch 6, Loss: 0.0549, Exact Match Ratio: 0.1520, Label-based Accuracy: 0.9836, F1 Score: 0.3090\n",
      "Epoch 7, Loss: 0.0538, Exact Match Ratio: 0.1610, Label-based Accuracy: 0.9839, F1 Score: 0.3291\n",
      "Epoch 8, Loss: 0.0529, Exact Match Ratio: 0.1654, Label-based Accuracy: 0.9840, F1 Score: 0.3447\n",
      "Epoch 9, Loss: 0.0522, Exact Match Ratio: 0.1711, Label-based Accuracy: 0.9842, F1 Score: 0.3544\n",
      "Epoch 10, Loss: 0.0516, Exact Match Ratio: 0.1745, Label-based Accuracy: 0.9843, F1 Score: 0.3609\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T22:57:40.576237Z",
     "start_time": "2024-11-11T22:57:40.183240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_directory = \"saved_model\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "model_path = os.path.join(save_directory, \"lora_model.pth\")\n",
    "\n",
    "\n",
    "def save_model(model, tokenizer, path=model_path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "    tokenizer.save_pretrained(save_directory)  # Save the tokenizer to the same directory\n",
    "\n",
    "\n",
    "# Save the model if training finished successfully\n",
    "if early_stop_counter < patience:\n",
    "    save_model(lora_model, tokenizer)\n",
    "else:\n",
    "    print(\"Early stopping occurred, model not saved.\")\n",
    "\n",
    "\n",
    "def load_model(path=model_path):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=number_of_tags)\n",
    "    lora_model = get_peft_model(model, lora_config)\n",
    "\n",
    "    # Load the saved state dictionary\n",
    "    lora_model.load_state_dict(torch.load(path))\n",
    "    print(f\"Model loaded from {path}\")\n",
    "\n",
    "    # Load the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
    "\n",
    "    return lora_model, tokenizer"
   ],
   "id": "618c4f46864bbbb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to saved_model\\lora_model.pth\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T22:58:22.455454Z",
     "start_time": "2024-11-11T22:57:40.586603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_tags(text):\n",
    "    lora_model.eval()\n",
    "    augmented_text = augment_with_context(text)  # Augment input text with context\n",
    "\n",
    "    # Print the augmented text\n",
    "    print(f\"Augmented Text: {augmented_text}\\n\")\n",
    "\n",
    "    inputs = tokenizer(augmented_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\").to(\n",
    "        device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = lora_model(**inputs).logits\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "    values_array = np.array(probs[0])\n",
    "    top_3_indices = np.argsort(values_array)[-3:]\n",
    "    result = np.zeros_like(values_array)\n",
    "    result[top_3_indices] = values_array[top_3_indices]\n",
    "\n",
    "    tags = (result > 0.5).astype(int)\n",
    "\n",
    "    if not tags.any():\n",
    "        tags[np.argmax(values_array)] = 1\n",
    "\n",
    "    return tags\n",
    "\n",
    "\n",
    "def binary_to_tags(binary_output, tag_list):\n",
    "    predicted_tags = [tag_list[i] for i in range(len(binary_output)) if binary_output[i] == 1]\n",
    "    return predicted_tags\n",
    "\n",
    "\n",
    "# Load model and tokenizer for future predictions\n",
    "loaded_model, loaded_tokenizer = load_model()\n",
    "loaded_model.to(device)\n",
    "\n",
    "\n",
    "def predict_tags_with_loaded_model(text):\n",
    "    loaded_model.eval()\n",
    "    augmented_text = augment_with_context(text)\n",
    "\n",
    "    # Print augmented text\n",
    "    print(f\"Augmented Text: {augmented_text}\\n\")\n",
    "\n",
    "    inputs = loaded_tokenizer(augmented_text, padding=\"max_length\", truncation=True, max_length=128,\n",
    "                              return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = loaded_model(**inputs).logits\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "    values_array = np.array(probs[0])\n",
    "    top_3_indices = np.argsort(values_array)[-3:]\n",
    "    result = np.zeros_like(values_array)\n",
    "    result[top_3_indices] = values_array[top_3_indices]\n",
    "\n",
    "    tags = (result > 0.5).astype(int)\n",
    "\n",
    "    if not tags.any():\n",
    "        tags[np.argmax(values_array)] = 1\n",
    "\n",
    "    return tags\n"
   ],
   "id": "fb4e933f82113720",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Abheek\\AppData\\Local\\Temp\\ipykernel_10500\\766398645.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from saved_model\\lora_model.pth\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T22:58:22.576069Z",
     "start_time": "2024-11-11T22:58:22.535869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_text = \"<p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the results.  Many computerized tools report test results in terms of p values or t values.</p>\\n\\n<p>How would you explain the following points to college students taking their first course in statistics:</p>\\n\\n<ul>\\n<li><p>What does a p-value mean in relation to the hypothesis being tested?  Are there cases when one should be looking for a high p-value or a low p-value?</p></li>\\n<li><p>What is the relationship between a p-value and a t-value?</p></li>\\n</ul>\\n\"\n",
    "\n",
    "predicted_tags = predict_tags_with_loaded_model(new_text)\n",
    "print(binary_to_tags(predicted_tags, all_tags))"
   ],
   "id": "12423dae6ebfc3f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Text: <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the results.  Many computerized tools report test results in terms of p values or t values.</p>\n",
      "\n",
      "<p>How would you explain the following points to college students taking their first course in statistics:</p>\n",
      "\n",
      "<ul>\n",
      "<li><p>What does a p-value mean in relation to the hypothesis being tested?  Are there cases when one should be looking for a high p-value or a low p-value?</p></li>\n",
      "<li><p>What is the relationship between a p-value and a t-value?</p></li>\n",
      "</ul>\n",
      " <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the results.  Many computerized tools report test results in terms of \"p values\" or \"t values\".</p>\n",
      "\n",
      "<p>How would you explain the following points to college students taking their first course in statistics:</p>\n",
      "\n",
      "<ul>\n",
      "<li><p>What does a \"p-value\" mean in relation to the hypothesis being tested?  Are there cases when one should be looking for a high p-value or a low p-value?</p></li>\n",
      "<li><p>What is the relationship between a p-value and a t-value?</p></li>\n",
      "</ul>\n",
      " <p>According to this thread</p>\n",
      "\n",
      "<p><a href=\"http://stats.stackexchange.com/questions/31/what-is-the-meaning-of-p-values-and-t-values-in-statistical-tests\">What is the meaning of p values and t values in statistical tests?</a></p>\n",
      "\n",
      "<p>a p-value essentially lets me compare the probability of tail-end (unlikely) events occurring and judging that against the significance level $\\alpha$ to decide whether the null hypothesis should be rejected. In the example on this thread, Muriel Bristol visits Fisher and it essentially asks what's the probability of getting 5/6 correct guesses given the probability of her guessing correctly is $0.5$. </p>\n",
      "\n",
      "<p>In the context of this, p-values make sense <em>if</em> I assume an unlikely event already happened. Because if such an event happens, then interpreting the significance of that event for a null hypothesis is a natural way to decide whether that hypothesis has been rejected. </p>\n",
      "\n",
      "<h2>My Question</h2>\n",
      "\n",
      "<p>Do p-values assume an unlikely event has already happened? If so, why is this part of the definition? If not, how does knowing the p-value tell me anything about why I should reject the null hypothesis? </p>\n",
      "\n",
      "<p>Without knowing an unlikely event occurred, it would seem all a p-value can say is \"if an unlikely event occurs, then the null hypothesis would be rejected.\" </p>\n",
      " <p>After looking into many blogs, I am completely confused understanding the T-test and the interpretation of the value.\n",
      "These are my understanding and confusions:</p>\n",
      "\n",
      "<ul>\n",
      "<li>Student T test is used to compare the Means of two groups</li>\n",
      "<li>T test is a Signal to Noise Ratio</li>\n",
      "<li>T test validates the sample when the population variance is not known</li>\n",
      "<li>T test is used when the sample size is very less</li>\n",
      "</ul>\n",
      "\n",
      "<p>These are the concrete statements used but know one explains the complete usage of T test and how does all these are applicable to use T test.<br>\n",
      "In the each statement, how to <strong>interpret the t value, t=2.23</strong>, what does this mean?</p>\n",
      "\n",
      "<p>Finally, what is T test and when to use it? Confused completely with each usage.</p>\n",
      "\n",
      "\n",
      "['hypothesis-testing', 'p-value']\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T11:39:54.029660Z",
     "start_time": "2024-11-12T11:39:52.491527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_text = \"<p>I have been looking into theoretical frameworks for method selection (note: not model selection) and have found very little systematic, mathematically-motivated work. By 'method selection', I mean a framework for distinguishing the appropriate (or better, optimal) method with respect to a problem, or problem type.</p>\\n\\n<p>What I have found is substantial, if piecemeal, work on particular methods and their tuning (i.e. prior selection in Bayesian methods), and method selection via bias selection (e.g. <a href=http://portal.acm.org/citation.cfm?id=218546>Inductive Policy: The Pragmatics of Bias Selection</a>). I may be unrealistic at this early stage of machine learning's development, but I was hoping to find something like what <a href=ftp://ftp.sas.com/pub/neural/measurement.html>measurement theory</a> does in prescribing admissible transformations and tests by scale type, only writ large in the arena of learning problems.</p>\\n\\n<p>Any suggestions?</p>\\n\"\n",
    "predicted_tags = predict_tags(new_text)\n",
    "\n",
    "print(binary_to_tags(predicted_tags, all_tags))"
   ],
   "id": "7bd4f9b2d8ad4266",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Text: <p>I have been looking into theoretical frameworks for method selection (note: not model selection) and have found very little systematic, mathematically-motivated work. By 'method selection', I mean a framework for distinguishing the appropriate (or better, optimal) method with respect to a problem, or problem type.</p>\n",
      "\n",
      "<p>What I have found is substantial, if piecemeal, work on particular methods and their tuning (i.e. prior selection in Bayesian methods), and method selection via bias selection (e.g. <a href=http://portal.acm.org/citation.cfm?id=218546>Inductive Policy: The Pragmatics of Bias Selection</a>). I may be unrealistic at this early stage of machine learning's development, but I was hoping to find something like what <a href=ftp://ftp.sas.com/pub/neural/measurement.html>measurement theory</a> does in prescribing admissible transformations and tests by scale type, only writ large in the arena of learning problems.</p>\n",
      "\n",
      "<p>Any suggestions?</p>\n",
      " <p>I have been looking into theoretical frameworks for method selection (note: not model selection) and have found very little systematic, mathematically-motivated work. By 'method selection', I mean a framework for distinguishing the appropriate (or better, optimal) method with respect to a problem, or problem type.</p>\n",
      "\n",
      "<p>What I have found is substantial, if piecemeal, work on particular methods and their tuning (i.e. prior selection in Bayesian methods), and method selection via bias selection (e.g. <a href=\"http://portal.acm.org/citation.cfm?id=218546\">Inductive Policy: The Pragmatics of Bias Selection</a>). I may be unrealistic at this early stage of machine learning's development, but I was hoping to find something like what <a href=\"ftp://ftp.sas.com/pub/neural/measurement.html\">measurement theory</a> does in prescribing admissible transformations and tests by scale type, only writ large in the arena of learning problems.</p>\n",
      "\n",
      "<p>Any suggestions?</p>\n",
      " <p>I've come across a rumour that some study showed that the performance of predictive models depends more on the expertise of the data analyst with the chosen method than on the choice of the method.<br>\n",
      "In other words, the claim is that it is more important that the data analyst is familiar with the chosen method than how \"appropriate\" the method would seem for the problem from a more theoretical standpoint.</p>\n",
      "\n",
      "<p>This was mentioned in the context of chemometrics, which involves typically problems of many variates (100s - 1000s), multiple collinearity, and of course, too few samples. Prediction may have been classification or regression.</p>\n",
      "\n",
      "<p>My personal experience suggests that this is <em>plausible</em>, but a study was mentioned (I asked the person who mentioned that by email after a quick but unsuccessful search, but never received any answer). However, also with a more elaborate search, I was not able to track down any papers.</p>\n",
      "\n",
      "<p>Is anyone aware of such findings? If not, what does the personal experience of Big Guys here say?</p>\n",
      " <p>No regular here will be unaware of the perils of using stepwise and similar automatic methods for variable selection in regression analysis. But preferred alternatives, such as the lasso or elasticnet, have there own difficulties.</p>\n",
      "\n",
      "<p>I can't find anywhere in the archive here a discussion of the methods provided by the <strong>subselect</strong> package in R, which I've just come across - the package has, so far as I can see, existed for a decade and more, and presumably has proved useful.</p>\n",
      "\n",
      "<p>In addition to a variation on the leaps procedure, <strong>subselect</strong> offers three algorithms (which it calls anneal, genetic and improve) for variable selection for different kinds of analysis. </p>\n",
      "\n",
      "<p>Have these procedures (or any of them) proved to be of value in variable selection? </p>\n",
      "\n",
      "\n",
      "['model-selection']\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "54fef1a8d98ed41b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
